{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing: Handling Amharic text, tokenization, and preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the scraped Amharic text data for tasks like tokenization, normalization, and handling Amharic-specific linguistic features, we need to follow several preprocessing steps tailored for the language. \n",
    "\n",
    "Hereâ€™s how we can approach this task:\n",
    "\n",
    "**Steps to Preprocess Amharic Text**\n",
    "\n",
    "- **Tokenization**: Tokenization is the process of splitting text into individual units such as words or subwords. Since Amharic uses a different script and has some unique linguistic features, tokenizing might need adjustments. \n",
    "    - Use specialized libraries that handle Amharic text or a custom rule-based tokenizer.\n",
    "\n",
    "- **Normalization**: This step involves cleaning and converting the text into a standard format:\n",
    "\n",
    "    - Remove special characters, punctuation, and numbers.\n",
    "    - Normalize similar-looking characters.\n",
    "    - Convert text to a standard form (for example, removing diacritics if necessary).\n",
    "\n",
    "- **Handling Amharic-Specific Features:**\n",
    "\n",
    "    - Amharic, like other Semitic languages, has specific features such as root-and-pattern morphology.\n",
    "\n",
    "    - Handling unique orthographic variants and considering suffixes, prefixes, and infixes in the language.\n",
    "\n",
    "    - Identifying verb conjugations, plural forms, and possessives for better tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the scraped Telegram data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from amharic_text_processor import AmharicTextPreprocessor  # type: ignore\n",
    "from amharic_labeler import AmharicNERLabeler  # type: ignore\n",
    "\n",
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data_path: str):\n",
    "        self.data_path = data_path\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.tokens = None\n",
    "        self.labeled_data = None\n",
    "\n",
    "    def explore_data(self):\n",
    "        \"\"\"Explores the first and last 5 rows of the dataset.\"\"\"\n",
    "        logger.info(\"Exploring the data...\")\n",
    "        logger.info(f\"First 5 rows: \\n{self.data.head()}\")\n",
    "        logger.info(f\"Last 5 rows: \\n{self.data.tail()}\")\n",
    "        logger.info(f\"Data shape: {self.data.shape}\")\n",
    "        logger.info(f\"Missing values: \\n{self.data.isnull().sum()}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess and tokenize the Amharic messages.\"\"\"\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        preprocessor = AmharicTextPreprocessor()\n",
    "        self.tokens = preprocessor.preprocess_dataframe(self.data, 'Message')\n",
    "\n",
    "    def drop_na(self):\n",
    "        \"\"\"Drops rows with missing values in the 'Message' column.\"\"\"\n",
    "        logger.info(\"Dropping NaN values in 'Message' column...\")\n",
    "        self.data.dropna(subset='Message', inplace=True)\n",
    "\n",
    "    def get_preprocessed_texts(self):\n",
    "        \"\"\"Returns a list of preprocessed messages.\"\"\"\n",
    "        preprocessed_texts = self.tokens['preprocessed_message'].dropna().tolist()\n",
    "        return pd.Series(preprocessed_texts).reset_index(name='message')\n",
    "\n",
    "class NERLabeler:\n",
    "    def __init__(self):\n",
    "        self.labeler = AmharicNERLabeler()\n",
    "\n",
    "    def label_data(self, df: pd.DataFrame):\n",
    "        \"\"\"Labels the tokens in the DataFrame.\"\"\"\n",
    "        logger.info(\"Labeling data...\")\n",
    "        df['Tokenized'] = df['message'].apply(lambda x: x.split())\n",
    "        labeled_df = self.labeler.label_dataframe(df, 'Tokenized')\n",
    "        return labeled_df\n",
    "\n",
    "    def save_labeled_data(self, labeled_df: pd.DataFrame, output_path: str):\n",
    "        \"\"\"Saves the labeled data in CoNLL format.\"\"\"\n",
    "        logger.info(f\"Saving labeled data to {output_path}...\")\n",
    "        self.labeler.save_conll_format(labeled_df, output_path)\n",
    "\n",
    "class AmharicTextPipeline:\n",
    "    def __init__(self, data_path: str, output_path: str):\n",
    "        self.data_processor = DataProcessor(data_path)\n",
    "        self.ner_labeler = NERLabeler()\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Run the full pipeline: preprocess, label, and save.\"\"\"\n",
    "        self.data_processor.explore_data()\n",
    "        self.data_processor.preprocess_data()\n",
    "        self.data_processor.drop_na()\n",
    "        preprocessed_df = self.data_processor.get_preprocessed_texts()\n",
    "        labeled_df = self.ner_labeler.label_data(preprocessed_df)\n",
    "        self.ner_labeler.save_labeled_data(labeled_df, self.output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the data and output paths\n",
    "    data_path = '../data/telegram_data.csv'\n",
    "    output_path = '../data/labeled_data_conll.conll'\n",
    "\n",
    "    # Run the pipeline\n",
    "    pipeline = AmharicTextPipeline(data_path, output_path)\n",
    "    pipeline.run_pipeline()\n",
    "\n",
    "    logger.info(\"Pipeline execution completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
